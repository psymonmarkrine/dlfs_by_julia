# 4章 ニューラルネットワークの学習

本章のテーマは、ニューラルネットワークの学習です。  
～  

## 4.1 データから学習する
### 4.1.1 データ駆動
### 4.1.2 訓練データとテストデータ
## 4.2 損失関数
### 4.2.1 2乗和誤差

損失関数として用いられる関数はいくつかありますが、もっとも有名ななものは**2乗和誤差**（sum of squared error）でしょう。  
～  

```julia
julia> y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0];

julia> t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0];

```

～  

```julia
function sum_squared_error(y, t)
    return 0.5 * sum((y-t).^2)
end
```

～  

```julia
julia> # 「3」を正解とする

julia> t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0];

julia>

julia> # 例１：「3」の確率が最も高い場合（0.6）

julia> y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0];

julia> sum_squared_error(y, t)
0.09750000000000003

julia>

julia> # 例１：「7」の確率が最も高い場合（0.6）

julia> y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0];

julia> sum_squared_error(y, t)
0.5974999999999999
```

ここでは2つの例を示しています。  
～  

### 4.2.2 交差エントロピー誤差

2乗和誤差と別の損失関数として、**交差エントロピー誤差**（cross entropy error）もよく用いられます。  
～  

```julia
julia> function cross_entropy_error(y, t)
           delta = 1.e-7
           return -sum(t .* log.(y .+ delta))
       end
cross_entropy_error (generic function with 1 method)

```

～  

```julia
julia> t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0];

julia> y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0];

julia> cross_entropy_error(y, t)
0.510825457099338

julia>

julia> y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0];

julia> cross_entropy_error(y, t)
2.302584092994546
```

～  

